{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rapidfuzz import fuzz, process  # Fuzzy matching for flexibility\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from nltk.corpus import wordnet\n",
    "from nltk import pos_tag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\nick_\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\nick_\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\nick_\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\nick_\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# Download all necessary NLTK resources\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger_eng')  # NEW - required for POS tagging\n",
    "\n",
    "# Initialize lemmatizer and stopword list\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words(\"english\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to convert NLTK POS to WordNet POS\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN  # fallback\n",
    "\n",
    "# Updated preprocess_text function\n",
    "def preprocess_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    words = text.lower().split()\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    tagged_words = pos_tag(words)\n",
    "\n",
    "    lemmatized_words = []\n",
    "    for word, pos in tagged_words:\n",
    "        wn_pos = get_wordnet_pos(pos)\n",
    "        lemma = lemmatizer.lemmatize(word, wn_pos)\n",
    "        if lemma == word and wn_pos != wordnet.VERB:\n",
    "            # Retry as verb if unchanged\n",
    "            lemma = lemmatizer.lemmatize(word, pos='v')\n",
    "        lemmatized_words.append(lemma)\n",
    "\n",
    "    return \" \".join(lemmatized_words)\n",
    "\n",
    "def remove_bracketed_words(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Remove all content inside brackets (including brackets)\n",
    "    cleaned_text = re.sub(r'\\s*\\([^)]*\\)', '', text).strip()\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "# Function to find synonyms using WordNet\n",
    "def get_synonyms(word):\n",
    "    synonyms = set()\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for lemma in syn.lemmas():\n",
    "            synonyms.add(lemma.name().replace(\"_\", \" \"))  # Convert underscores to spaces\n",
    "    return list(synonyms)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flattening the ESCO Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "file_path = \"../data/ESCO skill taxonomy dataset.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Columns containing skills\n",
    "skill_columns = [\n",
    "    \"Essential Skills (Skill)\",\n",
    "    \"Essential Skills (Knowledge)\",\n",
    "    \"Optional Skills (Skill)\",\n",
    "    \"Optional Skills (Knowledge)\"\n",
    "]\n",
    "\n",
    "# Ensure missing values are handled\n",
    "df[skill_columns] = df[skill_columns].fillna(\"\")\n",
    "\n",
    "# Split comma-separated skills into lists\n",
    "for col in skill_columns:\n",
    "    df[col] = df[col].apply(lambda x: x.split(\", \") if isinstance(x, str) else [])\n",
    "\n",
    "# Explode each skill column separately and merge back\n",
    "esco_taxonomy_df = df.copy()\n",
    "for col in skill_columns:\n",
    "    esco_taxonomy_df = esco_taxonomy_df.explode(col)\n",
    "\n",
    "# Rename columns for clarity\n",
    "esco_taxonomy_df = esco_taxonomy_df.rename(columns={\n",
    "    \"Occupation Title\": \"Job Role\",\n",
    "    \"ESCO Code\": \"ESCO Code\",\n",
    "    \"Description\": \"Job Description\",\n",
    "    \"Alternative Labels\": \"Alternative Titles\",\n",
    "    \"Essential Skills (Skill)\": \"Essential Skill\",\n",
    "    \"Essential Skills (Knowledge)\": \"Essential Knowledge\",\n",
    "    \"Optional Skills (Skill)\": \"Optional Skill\",\n",
    "    \"Optional Skills (Knowledge)\": \"Optional Knowledge\"\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_preprocess = [\n",
    "    \"Essential Skill\",\n",
    "    \"Essential Knowledge\",\n",
    "    \"Optional Skill\",\n",
    "    \"Optional Knowledge\"\n",
    "]\n",
    "\n",
    "for col in columns_to_preprocess:\n",
    "    unique_values = esco_taxonomy_df[col].dropna().unique()\n",
    "    processed_map = {val: preprocess_text(val) for val in unique_values}\n",
    "    esco_taxonomy_df[col] = esco_taxonomy_df[col].map(processed_map)\n",
    "\n",
    "esco_taxonomy_df[\"Essential Skill\"] = esco_taxonomy_df[\"Essential Skill\"].apply(remove_bracketed_words)\n",
    "esco_taxonomy_df[\"Essential Knowledge\"] = esco_taxonomy_df[\"Essential Knowledge\"].apply(remove_bracketed_words)\n",
    "esco_taxonomy_df[\"Optional Skill\"] = esco_taxonomy_df[\"Optional Skill\"].apply(remove_bracketed_words)\n",
    "esco_taxonomy_df[\"Optional Knowledge\"] = esco_taxonomy_df[\"Optional Knowledge\"].apply(remove_bracketed_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matching skills to jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set of all valid skills for fuzzy matching\n",
    "all_skills = set(\n",
    "    esco_taxonomy_df[\"Essential Skill\"].dropna().tolist() +\n",
    "    esco_taxonomy_df[\"Essential Knowledge\"].dropna().tolist() +\n",
    "    esco_taxonomy_df[\"Optional Skill\"].dropna().tolist() +\n",
    "    esco_taxonomy_df[\"Optional Knowledge\"].dropna().tolist()\n",
    ")\n",
    "\n",
    "essential_skills = set(    \n",
    "    esco_taxonomy_df[\"Essential Skill\"].dropna().tolist() +\n",
    "    esco_taxonomy_df[\"Essential Knowledge\"].dropna().tolist()\n",
    "    )\n",
    "\n",
    "optional_skills = set(    \n",
    "    esco_taxonomy_df[\"Optional Skill\"].dropna().tolist() +\n",
    "    esco_taxonomy_df[\"Optional Knowledge\"].dropna().tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../data/tools_grouped.csv\"\n",
    "\n",
    "# Load Technology Tool Mapping\n",
    "tech_tools_df = pd.read_csv(file_path)  # File containing tool-category mappings\n",
    "tool_to_category = {}\n",
    "\n",
    "for _, row in tech_tools_df.iterrows():\n",
    "    raw_category = row[\"Technology Tool\"]\n",
    "    raw_tools = row[\"Technology Tool Example\"].split(\", \")\n",
    "\n",
    "    # Preprocess the category name once\n",
    "    category = preprocess_text(raw_category)\n",
    "\n",
    "    for tool in raw_tools:\n",
    "        preprocessed_tool = preprocess_text(tool)\n",
    "        tool_to_category[preprocessed_tool] = category\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code performs intelligent matching between user-entered skills and job roles in the ESCO taxonomy, using a combination of fuzzy string matching and tool-category mapping. The map_skills_to_matched_tools() function takes an individual skill and tries to match it either directly to a known tool name or to a broader tool category using fuzzy matching (with a configurable similarity threshold). It returns the best-matching tool category based on score comparisons. The main function, match_jobs(), processes a list of user-input skills by first cleaning them and then attempting to match each one â€” prioritizing exact matches for short single-character skills (like \"R\"), followed by fuzzy matches against tools and the ESCO skills dataset. Top matches are selected based on similarity scores, and low-confidence or ambiguous matches are filtered out. Once the matching is done, the function aggregates all matched skills and compares them against job roles in the ESCO taxonomy by constructing a set of all skills (essential and optional) associated with each job. It counts how many matched user skills appear in each job's skill set, filters out roles with fewer than two matches, and returns a ranked list of job roles based on how well they align with the userâ€™s skills. The output includes the number of overlapping skills per job and displays the best-matching roles for easier interpretation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def map_skills_to_matched_tools(skill, threshold=85):\n",
    "    \"\"\"\n",
    "    Matches user-entered skill to either a tool or tool category based on fuzzy score.\n",
    "    Returns the best-matched tool category.\n",
    "    \"\"\"\n",
    "    tool_names = list(tool_to_category.keys())\n",
    "    tool_categories = list(set(tool_to_category.values()))\n",
    "    skill_lower = preprocess_text(skill)\n",
    "\n",
    "    # Fuzzy match with tool names\n",
    "    match_result_tool = process.extractOne(skill_lower, tool_names, scorer=fuzz.WRatio)\n",
    "    tool_match, tool_score = match_result_tool[:2] if match_result_tool else (None, 0)\n",
    "    tool_category = tool_to_category.get(tool_match) if tool_match else None\n",
    "\n",
    "    # Fuzzy match with category names\n",
    "    match_result_category = process.extractOne(skill_lower, tool_categories, scorer=fuzz.WRatio)\n",
    "    category_match, category_score = match_result_category[:2] if match_result_category else (None, 0)\n",
    "\n",
    "    # Decide based on best score\n",
    "    if tool_score >= threshold and (tool_score > category_score):\n",
    "        print(f\"ðŸ” '{skill}' matched to tool '{tool_match}' â†’ category '{tool_category}' (score: {tool_score})\")\n",
    "        return tool_category\n",
    "    elif category_score >= threshold:\n",
    "        print(f\"ðŸ” '{skill}' matched directly to category '{category_match}' (score: {category_score})\")\n",
    "        return category_match\n",
    "\n",
    "    # No good match\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "# Main Matching Function\n",
    "def match_skills_esco_fuzzy(user_skills, threshold): \n",
    "    \"\"\"\n",
    "    Matches user-entered skills with job roles using NLP + fuzzy matching.\n",
    "    Filters jobs that have at least 2 matched skills.\n",
    "    \"\"\"\n",
    "\n",
    "    matched_skills = set()\n",
    "\n",
    "    # Preprocess user input skills\n",
    "    user_skills = [preprocess_text(skill) for skill in user_skills]\n",
    "\n",
    "    # Ensure all_skills only contains valid skills\n",
    "    cleaned_skills = set(skill for skill in all_skills if isinstance(skill, str) and skill.strip())\n",
    "\n",
    "    # Perform fuzzy matching for each user skill\n",
    "    for skill in user_skills:\n",
    "        print(f\"\\nðŸ” Matching User Skill: {skill}\")\n",
    "\n",
    "        # âœ… Exact match logic for single-character user skills (e.g., \"r\")\n",
    "        if len(skill.strip()) == 1:\n",
    "            exact_matches = [s for s in cleaned_skills if s.strip().lower() == skill.strip().lower()]\n",
    "            if exact_matches:\n",
    "                matched_skills.add(exact_matches[0])\n",
    "                print(f\"âœ… Exact Match for Short Skill: {exact_matches[0]}\")\n",
    "            else:\n",
    "                print(\"âŒ No exact match found for short skill.\")\n",
    "            continue  # Skip fuzzy matching for this skill\n",
    "\n",
    "        # Tool match\n",
    "        tool_raw = map_skills_to_matched_tools(skill, threshold=threshold)\n",
    "        tool_match = preprocess_text(tool_raw) if tool_raw else None\n",
    "        tool_match_result = process.extractOne(tool_match, cleaned_skills, scorer=fuzz.WRatio) if tool_match else None\n",
    "        tool_best, tool_score = tool_match_result[:2] if tool_match_result else (None, 0)\n",
    "        print(f\"Found Tool Match (Tech Tool): {tool_best} with score: {tool_score}\")\n",
    "        # Fuzzy match top 5\n",
    "        top_matches = process.extract(skill, cleaned_skills, scorer=fuzz.WRatio, limit=5)\n",
    "        print(\"Top Matches:\")\n",
    "        for i, (match, score, _) in enumerate(top_matches, start=1):\n",
    "            print(f\"  {i}. {match} ({round(score, 1)})\")\n",
    "\n",
    "        # âœ… Match all top skills with the same max score above threshold\n",
    "        if tool_best and tool_score >= threshold and tool_score > top_matches[0][1]:\n",
    "            print(f\"âœ… Selected Tool Match (Tech Tool): {tool_best}\")\n",
    "            matched_skills.add(tool_best)\n",
    "        elif top_matches:\n",
    "            max_score = top_matches[0][1]\n",
    "            if max_score >= threshold:\n",
    "                for match, score, _ in top_matches:\n",
    "                    if score == max_score:\n",
    "                        # âœ… Prevent single-letter *matched* skills unless perfect match\n",
    "                        if len(match.strip()) == 1 and score < 100:\n",
    "                            print(f\"âš ï¸ Skipped short matched skill '{match}' (score: {score}) â€” not an exact match.\")\n",
    "                            continue\n",
    "                        matched_skills.add(match)\n",
    "                        print(f\"âœ… Selected Tie Match: {match} ({round(score, 1)})\")\n",
    "            elif tool_best and tool_score >= threshold:\n",
    "                matched_skills.add(tool_best)\n",
    "                print(f\"âœ… Selected Tool Match (Tech Tool): {tool_best}\")\n",
    "        else:\n",
    "            print(\"âŒ No good match found.\")\n",
    "\n",
    "    return matched_skills\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_skills_job(matched_skills):\n",
    "\n",
    "    matched_skills = set(skill.lower().strip() for skill in matched_skills)\n",
    "\n",
    "    if not matched_skills:\n",
    "        print(\"\\nðŸš« No valid matches found.\")\n",
    "        return pd.DataFrame(columns=[\"Job Role\", \"Matched Skills Count\"])\n",
    "\n",
    "\n",
    "    # Step 2: Create 'All Skills' column per job\n",
    "    esco_taxonomy_df[\"All Skills\"] = (\n",
    "        esco_taxonomy_df[\"Essential Skill\"].fillna(\"\").astype(str) + \", \" +\n",
    "        esco_taxonomy_df[\"Essential Knowledge\"].fillna(\"\").astype(str) + \", \" +\n",
    "        esco_taxonomy_df[\"Optional Skill\"].fillna(\"\").astype(str) + \", \" +\n",
    "        esco_taxonomy_df[\"Optional Knowledge\"].fillna(\"\").astype(str)\n",
    "    )\n",
    "\n",
    "    # Step 3: Group by Job and create a set of lowercase skill strings\n",
    "    job_skills_df = (\n",
    "        esco_taxonomy_df.groupby([\"Job Role\", \"Job Description\"])[\"All Skills\"]\n",
    "        .apply(lambda skills: set(s.strip().lower() for line in skills for s in line.split(\",\") if s.strip()))\n",
    "        .reset_index(name=\"All Skills Set\")\n",
    "    )\n",
    "\n",
    "    # Step 4: Count how many matched skills appear in each job\n",
    "    job_skills_df[\"Matched Skills Count\"] = job_skills_df[\"All Skills Set\"].apply(\n",
    "        lambda skills: len(matched_skills.intersection(skills))\n",
    "    )\n",
    "\n",
    "    # Step 5: Filter and sort\n",
    "    matched_jobs = job_skills_df[job_skills_df[\"Matched Skills Count\"] > 1].copy()\n",
    "    matched_jobs = matched_jobs.sort_values(by=\"Matched Skills Count\", ascending=False)\n",
    "\n",
    "    # Step 6: Display results\n",
    "    print(\"\\nðŸ“‹ Matched Jobs (At Least 2 Skills Matched):\")\n",
    "    print(\"-\" * 58)\n",
    "    print(\"| {:<30} | {:<20} |\".format(\"Job Role\", \"Matched Skills Count\"))\n",
    "    print(\"-\" * 58)\n",
    "    for _, row in matched_jobs.iterrows():\n",
    "        print(\"| {:<30} | {:<20} |\".format(row[\"Job Role\"], row[\"Matched Skills Count\"]))\n",
    "    print(\"-\" * 58)\n",
    "\n",
    "    return matched_jobs[[\"Job Role\", \"Matched Skills Count\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Matching User Skill: mysql\n",
      "ðŸ” 'mysql' matched to tool 'mysql' â†’ category 'database management software' (score: 100.0)\n",
      "Found Tool Match (Tech Tool): database with score: 90.0\n",
      "Top Matches:\n",
      "  1. mysql (100.0)\n",
      "  2. postgresql (67.5)\n",
      "  3. sql server integration service (67.5)\n",
      "  4. sql server (67.5)\n",
      "  5. ml (60.0)\n",
      "âœ… Selected Tie Match: mysql (100.0)\n",
      "\n",
      "ðŸ” Matching User Skill: postgresql\n",
      "ðŸ” 'postgresql' matched to tool 'postgresql' â†’ category 'database management software' (score: 100.0)\n",
      "Found Tool Match (Tech Tool): database with score: 90.0\n",
      "Top Matches:\n",
      "  1. postgresql (100.0)\n",
      "  2. mysql (67.5)\n",
      "  3. n1ql (60.0)\n",
      "  4. sparql (60.0)\n",
      "  5. ml (60.0)\n",
      "âœ… Selected Tie Match: postgresql (100.0)\n",
      "\n",
      "ðŸ” Matching User Skill: database backup recovery\n",
      "ðŸ” 'database backup recovery' matched to tool 'oracle database administration (dba)' â†’ category 'database management software' (score: 85.5)\n",
      "Found Tool Match (Tech Tool): database with score: 90.0\n",
      "Top Matches:\n",
      "  1. database (90.0)\n",
      "  2. manage database (85.5)\n",
      "  3. perform backup (85.5)\n",
      "  4. analyse pipeline database information (85.5)\n",
      "  5. use database (85.5)\n",
      "âœ… Selected Tie Match: database (90.0)\n",
      "\n",
      "ðŸ” Matching User Skill: performance tune\n",
      "ðŸ” 'performance tune' matched directly to category 'athlete performance injury monitor software' (score: 85.5)\n",
      "Found Tool Match (Tech Tool): software framework with score: 85.5\n",
      "Top Matches:\n",
      "  1. monitor system performance (85.5)\n",
      "  2. track key performance indicator (85.5)\n",
      "  3. ict performance analysis method (85.5)\n",
      "  4. monitor communication channels' performance (85.5)\n",
      "  5. maintain database performance (85.5)\n",
      "âœ… Selected Tie Match: monitor system performance (85.5)\n",
      "âœ… Selected Tie Match: track key performance indicator (85.5)\n",
      "âœ… Selected Tie Match: ict performance analysis method (85.5)\n",
      "âœ… Selected Tie Match: monitor communication channels' performance (85.5)\n",
      "âœ… Selected Tie Match: maintain database performance (85.5)\n",
      "\n",
      "ðŸ” Matching User Skill: sql\n",
      "ðŸ” 'sql' matched to tool 'microsoft sql server' â†’ category 'application server software' (score: 90.0)\n",
      "Found Tool Match (Tech Tool): software framework with score: 85.5\n",
      "Top Matches:\n",
      "  1. postgresql (90.0)\n",
      "  2. sql server (90.0)\n",
      "  3. mysql (90.0)\n",
      "  4. sparql (72.0)\n",
      "  5. qlikview expressor (72.0)\n",
      "âœ… Selected Tie Match: postgresql (90.0)\n",
      "âœ… Selected Tie Match: sql server (90.0)\n",
      "âœ… Selected Tie Match: mysql (90.0)\n",
      "\n",
      "ðŸ” Matching User Skill: store procedure\n",
      "Found Tool Match (Tech Tool): None with score: 0\n",
      "Top Matches:\n",
      "  1. store digital data system (85.5)\n",
      "  2. perform escalation procedure (85.5)\n",
      "  3. follow work procedure (71.2)\n",
      "  4. salt (60.0)\n",
      "  5. identify customer requirement (60.0)\n",
      "âœ… Selected Tie Match: store digital data system (85.5)\n",
      "âœ… Selected Tie Match: perform escalation procedure (85.5)\n",
      "\n",
      "ðŸ” Matching User Skill: data model\n",
      "ðŸ” 'data model' matched directly to category 'technical design model software (2d 3d)' (score: 85.5)\n",
      "Found Tool Match (Tech Tool): design component interface with score: 85.5\n",
      "Top Matches:\n",
      "  1. data model (100.0)\n",
      "  2. create data model (90.0)\n",
      "  3. manage quantitative data (85.5)\n",
      "  4. product data management (85.5)\n",
      "  5. manage key data protection (85.5)\n",
      "âœ… Selected Tie Match: data model (100.0)\n",
      "\n",
      "ðŸ” Matching User Skill: oracle\n",
      "ðŸ” 'oracle' matched to tool 'oracle jd edward enterpriseone' â†’ category 'account financial management system' (score: 90.0)\n",
      "Found Tool Match (Tech Tool): deploy ict system with score: 85.5\n",
      "Top Matches:\n",
      "  1. oracle data integrator (90.0)\n",
      "  2. r (90.0)\n",
      "  3. oracle relational database (90.0)\n",
      "  4. oracle warehouse builder (90.0)\n",
      "  5. design component interface (65.5)\n",
      "âœ… Selected Tie Match: oracle data integrator (90.0)\n",
      "âš ï¸ Skipped short matched skill 'r' (score: 90.0) â€” not an exact match.\n",
      "âœ… Selected Tie Match: oracle relational database (90.0)\n",
      "âœ… Selected Tie Match: oracle warehouse builder (90.0)\n",
      "\n",
      "ðŸ” Matching User Skill: etl\n",
      "Found Tool Match (Tech Tool): None with score: 0\n",
      "Top Matches:\n",
      "  1. visual studio .net (72.0)\n",
      "  2. outsource model (72.0)\n",
      "  3. plan digital market (72.0)\n",
      "  4. 3d model (72.0)\n",
      "  5. service-oriented model (72.0)\n",
      "\n",
      "ðŸ” Matching User Skill: index\n",
      "ðŸ” 'index' matched to tool 'valve index' â†’ category 'virtual reality technology' (score: 90.0)\n",
      "Found Tool Match (Tech Tool): distribute ledger technology vulnerability with score: 85.5\n",
      "Top Matches:\n",
      "  1. blockchain design pattern (72.0)\n",
      "  2. explain blockchain implication (68.4)\n",
      "  3. develop virtual game engine (67.5)\n",
      "  4. identify ict security risk (67.5)\n",
      "  5. identify customer requirement (67.5)\n",
      "âœ… Selected Tool Match (Tech Tool): distribute ledger technology vulnerability\n",
      "\n",
      "ðŸ“‹ Matched Jobs (At Least 2 Skills Matched):\n",
      "----------------------------------------------------------\n",
      "| Job Role                       | Matched Skills Count |\n",
      "----------------------------------------------------------\n",
      "| database integrator            | 7                    |\n",
      "| data centre operator           | 6                    |\n",
      "| data warehouse designer        | 6                    |\n",
      "| database administrator         | 6                    |\n",
      "| database designer              | 6                    |\n",
      "| database developer             | 6                    |\n",
      "| system configurator            | 5                    |\n",
      "| ICT system integration consultant | 3                    |\n",
      "| ICT security consultant        | 2                    |\n",
      "| ICT system analyst             | 2                    |\n",
      "| data analyst                   | 2                    |\n",
      "| data engineer                  | 2                    |\n",
      "| software analyst               | 2                    |\n",
      "| webmaster                      | 2                    |\n",
      "----------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Role</th>\n",
       "      <th>Matched Skills Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>database integrator</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>data centre operator</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>data warehouse designer</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>database administrator</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>database designer</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>database developer</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>system configurator</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ICT system integration consultant</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ICT security consultant</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ICT system analyst</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>data analyst</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>data engineer</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>software analyst</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>webmaster</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Job Role  Matched Skills Count\n",
       "55                database integrator                     7\n",
       "47               data centre operator                     6\n",
       "51            data warehouse designer                     6\n",
       "52             database administrator                     6\n",
       "53                  database designer                     6\n",
       "54                 database developer                     6\n",
       "75                system configurator                     5\n",
       "29  ICT system integration consultant                     3\n",
       "22            ICT security consultant                     2\n",
       "26                 ICT system analyst                     2\n",
       "46                       data analyst                     2\n",
       "48                      data engineer                     2\n",
       "71                   software analyst                     2\n",
       "82                          webmaster                     2"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cybersecurity_analyst_skills = [\"MySQL\", \"PostgreSQL\", \"Database backup and recovery\", \"Performance tuning\", \"SQL\", \"Stored procedures\", \"Data modelling\", \"Oracle\", \"ETL\", \"Indexing\"]\n",
    "\n",
    "found_skills = match_skills_esco_fuzzy(cybersecurity_analyst_skills, threshold=85)\n",
    "\n",
    "match_skills_job(found_skills)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code defines a two-step pipeline for matching user-provided skills to the ESCO skills taxonomy using sentence embeddings and cosine similarity. The prepare_esco_embeddings() function takes a raw set of ESCO skills, cleans it by removing empty strings and extra whitespace, and then uses the pre-trained Sentence-BERT model (all-MiniLM-L6-v2) to encode the cleaned skills into numerical embeddings. These embeddings represent the semantic meaning of each skill in vector space. The match_user_skills() function then preprocesses the user's input skills (e.g., lowercasing, stripping whitespace), encodes them using the same SBERT model, and compares them to the ESCO embeddings using cosine similarity. For each user skill, it identifies the top matching ESCO skill(s) and returns the results in a DataFrame showing the original user skill, the closest matched ESCO skill, and their similarity score. This approach enables semantic matching even when the exact phrasing of skills differs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_skill_embeddings(raw_skills):\n",
    "    \"\"\"\n",
    "    Cleans and encodes a set of ESCO skills using SBERT.\n",
    "    Returns the cleaned skill list, model, and embeddings.\n",
    "    \"\"\"\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "    # Case 1: Dictionary input\n",
    "    if isinstance(raw_skills, dict):\n",
    "        items = [\n",
    "            k.strip() for k in raw_skills.keys()\n",
    "            if isinstance(k, str) and k.strip() != ''\n",
    "        ]\n",
    "        embeddings = model.encode(items)\n",
    "        return items, model, embeddings, raw_skills\n",
    "\n",
    "    # Case 2: List or set input\n",
    "    elif isinstance(raw_skills, (list, set)):\n",
    "        items = [\n",
    "            s.strip() for s in raw_skills\n",
    "            if isinstance(s, str) and s.strip() != ''\n",
    "        ]\n",
    "        embeddings = model.encode(items)\n",
    "        return items, model, embeddings, None\n",
    "\n",
    "    else:\n",
    "        raise TypeError(\"Input must be a list, set, or dictionary.\")\n",
    "\n",
    "\n",
    "def match_user_skills(user_skills, skills, embeddings, model, threshold=0.7, top_k=1):\n",
    "    \"\"\"\n",
    "    Matches user-entered skills to a set of reference skills using cosine similarity.\n",
    "    Returns a nicely printed DataFrame of best matches and the matched skills list.\n",
    "    \"\"\"\n",
    "    matched_skills = []\n",
    "    user_skills = [preprocess_text(skill) for skill in user_skills]\n",
    "    user_embeddings = model.encode(user_skills)\n",
    "\n",
    "    records = []\n",
    "\n",
    "    for i, user_emb in enumerate(user_embeddings):\n",
    "        sims = cosine_similarity([user_emb], embeddings)[0]\n",
    "        top_indices = sims.argsort()[::-1][:top_k]\n",
    "\n",
    "        best_match_idx = top_indices[0]\n",
    "        best_score = sims[best_match_idx]\n",
    "\n",
    "        if best_score >= threshold:\n",
    "            matched_skill = skills[best_match_idx]\n",
    "            matched_skills.append(matched_skill)\n",
    "        else:\n",
    "            matched_skill = \"No Match\"\n",
    "\n",
    "        records.append({\n",
    "            \"User Skill\": user_skills[i],\n",
    "            \"Matched Skill\": matched_skill,\n",
    "            \"Cosine Similarity\": round(best_score, 3)\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(records)\n",
    "\n",
    "    # âœ… Pretty print\n",
    "    print(\"\\nðŸ“‹ Skill Matching Results\")\n",
    "    print(\"-\" * 60)\n",
    "    print(df.to_markdown(index=False))\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    return matched_skills\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "esco_skills, esco_model, esco_embeddings, _ = prepare_skill_embeddings(all_skills)\n",
    "\n",
    "anzsco_skills, anzsco_model, anzsco_embeddings, anzsco_lookup  = prepare_skill_embeddings(tool_to_category)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“‹ Skill Matching Results\n",
      "------------------------------------------------------------\n",
      "| User Skill             | Matched Skill                        |   Cosine Similarity |\n",
      "|:-----------------------|:-------------------------------------|--------------------:|\n",
      "| sql                    | sql server                           |               0.736 |\n",
      "| microsoft excel        | No Match                             |               0.548 |\n",
      "| power bi               | No Match                             |               0.369 |\n",
      "| tableau                | No Match                             |               0.382 |\n",
      "| python (pandas, numpy) | No Match                             |               0.513 |\n",
      "| data clean             | perform data cleanse                 |               0.843 |\n",
      "| statistical analysis   | apply statistical analysis technique |               0.717 |\n",
      "| data visualization     | No Match                             |               0.56  |\n",
      "| a/b test               | No Match                             |               0.373 |\n",
      "| business acumen        | apply business acumen                |               0.803 |\n",
      "------------------------------------------------------------\n",
      "\n",
      "ðŸ“‹ Skill Matching Results\n",
      "------------------------------------------------------------\n",
      "| User Skill             | Matched Skill      |   Cosine Similarity |\n",
      "|:-----------------------|:-------------------|--------------------:|\n",
      "| sql                    | No Match           |               0.687 |\n",
      "| microsoft excel        | No Match           |               0.507 |\n",
      "| power bi               | microsoft power bi |               0.835 |\n",
      "| tableau                | tableau            |               1     |\n",
      "| python (pandas, numpy) | No Match           |               0.513 |\n",
      "| data clean             | No Match           |               0.428 |\n",
      "| statistical analysis   | No Match           |               0.649 |\n",
      "| data visualization     | No Match           |               0.501 |\n",
      "| a/b test               | No Match           |               0.306 |\n",
      "| business acumen        | No Match           |               0.475 |\n",
      "------------------------------------------------------------\n",
      "\n",
      "ðŸ“‹ Skill Matching Results\n",
      "------------------------------------------------------------\n",
      "| User Skill                                      | Matched Skill                        |   Cosine Similarity |\n",
      "|:------------------------------------------------|:-------------------------------------|--------------------:|\n",
      "| business intelligence decision support software | business intelligence                |               0.762 |\n",
      "| statistical data analysis software              | statistical analysis system software |               0.939 |\n",
      "------------------------------------------------------------\n",
      "\n",
      "ðŸ“‹ Matched Jobs (At Least 2 Skills Matched):\n",
      "----------------------------------------------------------\n",
      "| Job Role                       | Matched Skills Count |\n",
      "----------------------------------------------------------\n",
      "| data analyst                   | 3                    |\n",
      "| database integrator            | 3                    |\n",
      "| computer scientist             | 2                    |\n",
      "| computer vision engineer       | 2                    |\n",
      "| data scientist                 | 2                    |\n",
      "| database administrator         | 2                    |\n",
      "----------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Role</th>\n",
       "      <th>Matched Skills Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>data analyst</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>database integrator</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>computer scientist</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>computer vision engineer</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>data scientist</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>database administrator</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Job Role  Matched Skills Count\n",
       "46              data analyst                     3\n",
       "55       database integrator                     3\n",
       "44        computer scientist                     2\n",
       "45  computer vision engineer                     2\n",
       "50            data scientist                     2\n",
       "52    database administrator                     2"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_analyst = [\n",
    "        \"SQL\",\n",
    "        \"Microsoft Excel\",\n",
    "        \"Power BI\",\n",
    "        \"Tableau\",\n",
    "        \"Python (Pandas, NumPy)\",\n",
    "        \"Data cleaning\",\n",
    "        \"Statistical analysis\",\n",
    "        \"Data visualization\",\n",
    "        \"A/B testing\",\n",
    "        \"Business acumen\"\n",
    "\n",
    "    ]\n",
    "esco_matches = match_user_skills(data_analyst, esco_skills, esco_embeddings, esco_model, 0.70)\n",
    "\n",
    "anzsco_tool_matches = match_user_skills(data_analyst, anzsco_skills, anzsco_embeddings, anzsco_model, 0.70)\n",
    "\n",
    "tools_found_list = []\n",
    "for tool in anzsco_tool_matches:\n",
    "    tools_found_list.append(tool_to_category[tool])\n",
    "\n",
    "esco_tool_matches = match_user_skills(tools_found_list, esco_skills, esco_embeddings, esco_model, 0.70)\n",
    "\n",
    "combined_matches = esco_tool_matches + esco_matches\n",
    "\n",
    "match_skills_job(combined_matches)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
