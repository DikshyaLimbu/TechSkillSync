{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rapidfuzz import fuzz, process  # Fuzzy matching for flexibility\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from nltk.corpus import wordnet\n",
    "from nltk import pos_tag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\nick_\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\nick_\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\nick_\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\nick_\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# Download all necessary NLTK resources\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger_eng')  # NEW - required for POS tagging\n",
    "\n",
    "# Initialize lemmatizer and stopword list\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words(\"english\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to convert NLTK POS to WordNet POS\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN  # fallback\n",
    "\n",
    "# Updated preprocess_text function\n",
    "def preprocess_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    words = text.lower().split()\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    tagged_words = pos_tag(words)\n",
    "\n",
    "    lemmatized_words = []\n",
    "    for word, pos in tagged_words:\n",
    "        wn_pos = get_wordnet_pos(pos)\n",
    "        lemma = lemmatizer.lemmatize(word, wn_pos)\n",
    "        if lemma == word and wn_pos != wordnet.VERB:\n",
    "            # Retry as verb if unchanged\n",
    "            lemma = lemmatizer.lemmatize(word, pos='v')\n",
    "        lemmatized_words.append(lemma)\n",
    "\n",
    "    return \" \".join(lemmatized_words)\n",
    "\n",
    "def remove_bracketed_words(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Remove all content inside brackets (including brackets)\n",
    "    cleaned_text = re.sub(r'\\s*\\([^)]*\\)', '', text).strip()\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "# Function to find synonyms using WordNet\n",
    "def get_synonyms(word):\n",
    "    synonyms = set()\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for lemma in syn.lemmas():\n",
    "            synonyms.add(lemma.name().replace(\"_\", \" \"))  # Convert underscores to spaces\n",
    "    return list(synonyms)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flattening the ESCO Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "file_path = \"../data/ESCO skill taxonomy dataset.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Columns containing skills\n",
    "skill_columns = [\n",
    "    \"Essential Skills (Skill)\",\n",
    "    \"Essential Skills (Knowledge)\",\n",
    "    \"Optional Skills (Skill)\",\n",
    "    \"Optional Skills (Knowledge)\"\n",
    "]\n",
    "\n",
    "# Ensure missing values are handled\n",
    "df[skill_columns] = df[skill_columns].fillna(\"\")\n",
    "\n",
    "# Split comma-separated skills into lists\n",
    "for col in skill_columns:\n",
    "    df[col] = df[col].apply(lambda x: x.split(\", \") if isinstance(x, str) else [])\n",
    "\n",
    "# Explode each skill column separately and merge back\n",
    "esco_taxonomy_df = df.copy()\n",
    "for col in skill_columns:\n",
    "    esco_taxonomy_df = esco_taxonomy_df.explode(col)\n",
    "\n",
    "# Rename columns for clarity\n",
    "esco_taxonomy_df = esco_taxonomy_df.rename(columns={\n",
    "    \"Occupation Title\": \"Job Role\",\n",
    "    \"ESCO Code\": \"ESCO Code\",\n",
    "    \"Description\": \"Job Description\",\n",
    "    \"Alternative Labels\": \"Alternative Titles\",\n",
    "    \"Essential Skills (Skill)\": \"Essential Skill\",\n",
    "    \"Essential Skills (Knowledge)\": \"Essential Knowledge\",\n",
    "    \"Optional Skills (Skill)\": \"Optional Skill\",\n",
    "    \"Optional Skills (Knowledge)\": \"Optional Knowledge\"\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_preprocess = [\n",
    "    \"Essential Skill\",\n",
    "    \"Essential Knowledge\",\n",
    "    \"Optional Skill\",\n",
    "    \"Optional Knowledge\"\n",
    "]\n",
    "\n",
    "for col in columns_to_preprocess:\n",
    "    unique_values = esco_taxonomy_df[col].dropna().unique()\n",
    "    processed_map = {val: preprocess_text(val) for val in unique_values}\n",
    "    esco_taxonomy_df[col] = esco_taxonomy_df[col].map(processed_map)\n",
    "\n",
    "esco_taxonomy_df[\"Essential Skill\"] = esco_taxonomy_df[\"Essential Skill\"].apply(remove_bracketed_words)\n",
    "esco_taxonomy_df[\"Essential Knowledge\"] = esco_taxonomy_df[\"Essential Knowledge\"].apply(remove_bracketed_words)\n",
    "esco_taxonomy_df[\"Optional Skill\"] = esco_taxonomy_df[\"Optional Skill\"].apply(remove_bracketed_words)\n",
    "esco_taxonomy_df[\"Optional Knowledge\"] = esco_taxonomy_df[\"Optional Knowledge\"].apply(remove_bracketed_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matching skills to jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set of all valid skills for fuzzy matching\n",
    "all_skills = set(\n",
    "    esco_taxonomy_df[\"Essential Skill\"].dropna().tolist() +\n",
    "    esco_taxonomy_df[\"Essential Knowledge\"].dropna().tolist() +\n",
    "    esco_taxonomy_df[\"Optional Skill\"].dropna().tolist() +\n",
    "    esco_taxonomy_df[\"Optional Knowledge\"].dropna().tolist()\n",
    ")\n",
    "\n",
    "essential_skills = set(    \n",
    "    esco_taxonomy_df[\"Essential Skill\"].dropna().tolist() +\n",
    "    esco_taxonomy_df[\"Essential Knowledge\"].dropna().tolist()\n",
    "    )\n",
    "\n",
    "optional_skills = set(    \n",
    "    esco_taxonomy_df[\"Optional Skill\"].dropna().tolist() +\n",
    "    esco_taxonomy_df[\"Optional Knowledge\"].dropna().tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../data/tools_grouped.csv\"\n",
    "\n",
    "# Load Technology Tool Mapping\n",
    "tech_tools_df = pd.read_csv(file_path)  # File containing tool-category mappings\n",
    "tool_to_category = {}\n",
    "\n",
    "for _, row in tech_tools_df.iterrows():\n",
    "    raw_category = row[\"Technology Tool\"]\n",
    "    raw_tools = row[\"Technology Tool Example\"].split(\", \")\n",
    "\n",
    "    # Preprocess the category name once\n",
    "    category = preprocess_text(raw_category)\n",
    "\n",
    "    for tool in raw_tools:\n",
    "        preprocessed_tool = preprocess_text(tool)\n",
    "        tool_to_category[preprocessed_tool] = category\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code performs intelligent matching between user-entered skills and job roles in the ESCO taxonomy, using a combination of fuzzy string matching and tool-category mapping. The map_skills_to_matched_tools() function takes an individual skill and tries to match it either directly to a known tool name or to a broader tool category using fuzzy matching (with a configurable similarity threshold). It returns the best-matching tool category based on score comparisons. The main function, match_jobs(), processes a list of user-input skills by first cleaning them and then attempting to match each one â€” prioritizing exact matches for short single-character skills (like \"R\"), followed by fuzzy matches against tools and the ESCO skills dataset. Top matches are selected based on similarity scores, and low-confidence or ambiguous matches are filtered out. Once the matching is done, the function aggregates all matched skills and compares them against job roles in the ESCO taxonomy by constructing a set of all skills (essential and optional) associated with each job. It counts how many matched user skills appear in each job's skill set, filters out roles with fewer than two matches, and returns a ranked list of job roles based on how well they align with the userâ€™s skills. The output includes the number of overlapping skills per job and displays the best-matching roles for easier interpretation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def map_skills_to_matched_tools(skill, threshold=85):\n",
    "    \"\"\"\n",
    "    Matches user-entered skill to either a tool or tool category based on fuzzy score.\n",
    "    Returns the best-matched tool category.\n",
    "    \"\"\"\n",
    "    tool_names = list(tool_to_category.keys())\n",
    "    tool_categories = list(set(tool_to_category.values()))\n",
    "    skill_lower = preprocess_text(skill)\n",
    "\n",
    "    # Fuzzy match with tool names\n",
    "    match_result_tool = process.extractOne(skill_lower, tool_names, scorer=fuzz.WRatio)\n",
    "    tool_match, tool_score = match_result_tool[:2] if match_result_tool else (None, 0)\n",
    "    tool_category = tool_to_category.get(tool_match) if tool_match else None\n",
    "\n",
    "    # Fuzzy match with category names\n",
    "    match_result_category = process.extractOne(skill_lower, tool_categories, scorer=fuzz.WRatio)\n",
    "    category_match, category_score = match_result_category[:2] if match_result_category else (None, 0)\n",
    "\n",
    "    # Decide based on best score\n",
    "    if tool_score >= threshold and (tool_score > category_score):\n",
    "        print(f\"ðŸ” '{skill}' matched to tool '{tool_match}' â†’ category '{tool_category}' (score: {tool_score})\")\n",
    "        return tool_category\n",
    "    elif category_score >= threshold:\n",
    "        print(f\"ðŸ” '{skill}' matched directly to category '{category_match}' (score: {category_score})\")\n",
    "        return category_match\n",
    "\n",
    "    # No good match\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "# Main Matching Function\n",
    "def match_skills_esco_fuzzy(user_skills, threshold): \n",
    "    \"\"\"\n",
    "    Matches user-entered skills with job roles using NLP + fuzzy matching.\n",
    "    Filters jobs that have at least 2 matched skills.\n",
    "    \"\"\"\n",
    "\n",
    "    matched_skills = set()\n",
    "\n",
    "    # Preprocess user input skills\n",
    "    user_skills = [preprocess_text(skill) for skill in user_skills]\n",
    "\n",
    "    # Ensure all_skills only contains valid skills\n",
    "    cleaned_skills = set(skill for skill in all_skills if isinstance(skill, str) and skill.strip())\n",
    "\n",
    "    # Perform fuzzy matching for each user skill\n",
    "    for skill in user_skills:\n",
    "        print(f\"\\nðŸ” Matching User Skill: {skill}\")\n",
    "\n",
    "        # âœ… Exact match logic for single-character user skills (e.g., \"r\")\n",
    "        if len(skill.strip()) == 1:\n",
    "            exact_matches = [s for s in cleaned_skills if s.strip().lower() == skill.strip().lower()]\n",
    "            if exact_matches:\n",
    "                matched_skills.add(exact_matches[0])\n",
    "                print(f\"âœ… Exact Match for Short Skill: {exact_matches[0]}\")\n",
    "            else:\n",
    "                print(\"âŒ No exact match found for short skill.\")\n",
    "            continue  # Skip fuzzy matching for this skill\n",
    "\n",
    "        # Tool match\n",
    "        tool_raw = map_skills_to_matched_tools(skill, threshold=threshold)\n",
    "        tool_match = preprocess_text(tool_raw) if tool_raw else None\n",
    "        tool_match_result = process.extractOne(tool_match, cleaned_skills, scorer=fuzz.WRatio) if tool_match else None\n",
    "        tool_best, tool_score = tool_match_result[:2] if tool_match_result else (None, 0)\n",
    "        print(f\"Found Tool Match (Tech Tool): {tool_best} with score: {tool_score}\")\n",
    "        # Fuzzy match top 5\n",
    "        top_matches = process.extract(skill, cleaned_skills, scorer=fuzz.WRatio, limit=5)\n",
    "        print(\"Top Matches:\")\n",
    "        for i, (match, score, _) in enumerate(top_matches, start=1):\n",
    "            print(f\"  {i}. {match} ({round(score, 1)})\")\n",
    "\n",
    "        # âœ… Match all top skills with the same max score above threshold\n",
    "        if tool_best and tool_score >= threshold and tool_score > top_matches[0][1]:\n",
    "            print(f\"âœ… Selected Tool Match (Tech Tool): {tool_best}\")\n",
    "            matched_skills.add(tool_best)\n",
    "        elif top_matches:\n",
    "            max_score = top_matches[0][1]\n",
    "            if max_score >= threshold:\n",
    "                for match, score, _ in top_matches:\n",
    "                    if score == max_score:\n",
    "                        # âœ… Prevent single-letter *matched* skills unless perfect match\n",
    "                        if len(match.strip()) == 1 and score < 100:\n",
    "                            print(f\"âš ï¸ Skipped short matched skill '{match}' (score: {score}) â€” not an exact match.\")\n",
    "                            continue\n",
    "                        matched_skills.add(match)\n",
    "                        print(f\"âœ… Selected Tie Match: {match} ({round(score, 1)})\")\n",
    "            elif tool_best and tool_score >= threshold:\n",
    "                matched_skills.add(tool_best)\n",
    "                print(f\"âœ… Selected Tool Match (Tech Tool): {tool_best}\")\n",
    "        else:\n",
    "            print(\"âŒ No good match found.\")\n",
    "\n",
    "    return matched_skills\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_skills_job(matched_skills):\n",
    "\n",
    "    matched_skills = set(skill.lower().strip() for skill in matched_skills)\n",
    "\n",
    "    if not matched_skills:\n",
    "        print(\"\\nðŸš« No valid matches found.\")\n",
    "        return pd.DataFrame(columns=[\"Job Role\", \"Matched Skills Count\"])\n",
    "\n",
    "\n",
    "    # Step 2: Create 'All Skills' column per job\n",
    "    esco_taxonomy_df[\"All Skills\"] = (\n",
    "        esco_taxonomy_df[\"Essential Skill\"].fillna(\"\").astype(str) + \", \" +\n",
    "        esco_taxonomy_df[\"Essential Knowledge\"].fillna(\"\").astype(str) + \", \" +\n",
    "        esco_taxonomy_df[\"Optional Skill\"].fillna(\"\").astype(str) + \", \" +\n",
    "        esco_taxonomy_df[\"Optional Knowledge\"].fillna(\"\").astype(str)\n",
    "    )\n",
    "\n",
    "    # Step 3: Group by Job and create a set of lowercase skill strings\n",
    "    job_skills_df = (\n",
    "        esco_taxonomy_df.groupby([\"Job Role\", \"Job Description\"])[\"All Skills\"]\n",
    "        .apply(lambda skills: set(s.strip().lower() for line in skills for s in line.split(\",\") if s.strip()))\n",
    "        .reset_index(name=\"All Skills Set\")\n",
    "    )\n",
    "\n",
    "    # Step 4: Count how many matched skills appear in each job\n",
    "    job_skills_df[\"Matched Skills Count\"] = job_skills_df[\"All Skills Set\"].apply(\n",
    "        lambda skills: len(matched_skills.intersection(skills))\n",
    "    )\n",
    "\n",
    "    # Step 5: Filter and sort\n",
    "    matched_jobs = job_skills_df[job_skills_df[\"Matched Skills Count\"] > 1].copy()\n",
    "    matched_jobs = matched_jobs.sort_values(by=\"Matched Skills Count\", ascending=False)\n",
    "\n",
    "    # Step 6: Display results\n",
    "    print(\"\\nðŸ“‹ Matched Jobs (At Least 2 Skills Matched):\")\n",
    "    print(\"-\" * 58)\n",
    "    print(\"| {:<30} | {:<20} |\".format(\"Job Role\", \"Matched Skills Count\"))\n",
    "    print(\"-\" * 58)\n",
    "    for _, row in matched_jobs.iterrows():\n",
    "        print(\"| {:<30} | {:<20} |\".format(row[\"Job Role\"], row[\"Matched Skills Count\"]))\n",
    "    print(\"-\" * 58)\n",
    "\n",
    "    return matched_jobs[[\"Job Role\", \"Matched Skills Count\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Matching User Skill: network security\n",
      "ðŸ” 'network security' matched directly to category 'network security virtual private network vpn software' (score: 90.0)\n",
      "Found Tool Match (Tech Tool): develop virtual game engine with score: 85.5\n",
      "Top Matches:\n",
      "  1. ict network security risk (90.0)\n",
      "  2. identify ict security risk (85.5)\n",
      "  3. network management system tool (85.5)\n",
      "  4. advise strengthen security (85.5)\n",
      "  5. analyse network bandwidth requirement (85.5)\n",
      "âœ… Selected Tie Match: ict network security risk (90.0)\n",
      "\n",
      "ðŸ” Matching User Skill: siem (e.g., splunk)\n",
      "ðŸ” 'siem (e.g., splunk)' matched to tool 'splunk siem' â†’ category 'network monitor software' (score: 85.5)\n",
      "Found Tool Match (Tech Tool): author software with score: 85.5\n",
      "Top Matches:\n",
      "  1. apl (60.0)\n",
      "  2. ansible (54.0)\n",
      "  3. swift (51.4)\n",
      "  4. mysql (51.3)\n",
      "  5. implement strategic plan (46.5)\n",
      "âœ… Selected Tool Match (Tech Tool): author software\n",
      "\n",
      "ðŸ” Matching User Skill: threat analysis\n",
      "ðŸ” 'threat analysis' matched directly to category 'motion analysis software' (score: 85.5)\n",
      "Found Tool Match (Tech Tool): provide cost benefit analysis report with score: 85.5\n",
      "Top Matches:\n",
      "  1. provide cost benefit analysis report (85.5)\n",
      "  2. statistical analysis system software (85.5)\n",
      "  3. perform business analysis (85.5)\n",
      "  4. apply statistical analysis technique (85.5)\n",
      "  5. web application security threat (85.5)\n",
      "âœ… Selected Tie Match: provide cost benefit analysis report (85.5)\n",
      "âœ… Selected Tie Match: statistical analysis system software (85.5)\n",
      "âœ… Selected Tie Match: perform business analysis (85.5)\n",
      "âœ… Selected Tie Match: apply statistical analysis technique (85.5)\n",
      "âœ… Selected Tie Match: web application security threat (85.5)\n",
      "\n",
      "ðŸ” Matching User Skill: vulnerability assessment\n",
      "Found Tool Match (Tech Tool): None with score: 0\n",
      "Top Matches:\n",
      "  1. perform security vulnerability assessment (90.0)\n",
      "  2. distribute ledger technology vulnerability (85.5)\n",
      "  3. data quality assessment (72.3)\n",
      "  4. jsss (67.5)\n",
      "  5. less (67.5)\n",
      "âœ… Selected Tie Match: perform security vulnerability assessment (90.0)\n",
      "\n",
      "ðŸ” Matching User Skill: firewall intrusion detection system\n",
      "ðŸ” 'firewall intrusion detection system' matched directly to category 'data management system' (score: 85.5)\n",
      "Found Tool Match (Tech Tool): database management system with score: 91.66666666666666\n",
      "Top Matches:\n",
      "  1. deploy ict system (85.5)\n",
      "  2. maintain ict system (85.5)\n",
      "  3. apply ict system theory (85.5)\n",
      "  4. system think (85.5)\n",
      "  5. use ict ticket system (85.5)\n",
      "âœ… Selected Tool Match (Tech Tool): database management system\n",
      "\n",
      "ðŸ” Matching User Skill: risk assessment\n",
      "ðŸ” 'risk assessment' matched to tool 'ecological risk assessment software' â†’ category 'science engineer software' (score: 90.0)\n",
      "Found Tool Match (Tech Tool): author software with score: 85.5\n",
      "Top Matches:\n",
      "  1. apply risk management process (85.5)\n",
      "  2. identify ict security risk (85.5)\n",
      "  3. ict network security risk (85.5)\n",
      "  4. data quality assessment (85.5)\n",
      "  5. implement ict risk management (85.5)\n",
      "âœ… Selected Tie Match: apply risk management process (85.5)\n",
      "âœ… Selected Tie Match: identify ict security risk (85.5)\n",
      "âœ… Selected Tie Match: ict network security risk (85.5)\n",
      "âœ… Selected Tie Match: data quality assessment (85.5)\n",
      "âœ… Selected Tie Match: implement ict risk management (85.5)\n",
      "\n",
      "ðŸ” Matching User Skill: incident response\n",
      "ðŸ” 'incident response' matched directly to category 'voice recognition response software' (score: 85.5)\n",
      "Found Tool Match (Tech Tool): software framework with score: 85.5\n",
      "Top Matches:\n",
      "  1. respond incident cloud (73.1)\n",
      "  2. maintain responsive design (68.8)\n",
      "  3. nexpose (64.3)\n",
      "  4. linq (60.0)\n",
      "  5. r (60.0)\n",
      "âœ… Selected Tool Match (Tech Tool): software framework\n",
      "\n",
      "ðŸ” Matching User Skill: encryption technique\n",
      "Found Tool Match (Tech Tool): None with score: 0\n",
      "Top Matches:\n",
      "  1. implement data warehouse technique (85.5)\n",
      "  2. apply statistical analysis technique (85.5)\n",
      "  3. business requirement technique (85.5)\n",
      "  4. ict problem management technique (85.5)\n",
      "  5. social medium market technique (85.5)\n",
      "âœ… Selected Tie Match: implement data warehouse technique (85.5)\n",
      "âœ… Selected Tie Match: apply statistical analysis technique (85.5)\n",
      "âœ… Selected Tie Match: business requirement technique (85.5)\n",
      "âœ… Selected Tie Match: ict problem management technique (85.5)\n",
      "âœ… Selected Tie Match: social medium market technique (85.5)\n",
      "\n",
      "ðŸ” Matching User Skill: security policy\n",
      "ðŸ” 'security policy' matched directly to category 'network security virtual private network vpn software' (score: 85.5)\n",
      "Found Tool Match (Tech Tool): develop virtual game engine with score: 85.5\n",
      "Top Matches:\n",
      "  1. define security policy (95.0)\n",
      "  2. apply information security policy (90.0)\n",
      "  3. apply system organisational policy (85.5)\n",
      "  4. ict environmental policy (85.5)\n",
      "  5. identify ict security risk (85.5)\n",
      "âœ… Selected Tie Match: define security policy (95.0)\n",
      "\n",
      "ðŸ” Matching User Skill: linux\n",
      "Found Tool Match (Tech Tool): None with score: 0\n",
      "Top Matches:\n",
      "  1. linq (66.7)\n",
      "  2. ml (60.0)\n",
      "  3. meet deadline (60.0)\n",
      "  4. adhere organisational guideline (60.0)\n",
      "  5. industrial software (60.0)\n",
      "\n",
      "ðŸ“‹ Matched Jobs (At Least 2 Skills Matched):\n",
      "----------------------------------------------------------\n",
      "| Job Role                       | Matched Skills Count |\n",
      "----------------------------------------------------------\n",
      "| ICT resilience manager         | 6                    |\n",
      "| ICT security manager           | 6                    |\n",
      "| ethical hacker                 | 5                    |\n",
      "| ICT disaster recovery analyst  | 4                    |\n",
      "| ICT security consultant        | 4                    |\n",
      "| chief ICT security officer     | 3                    |\n",
      "| ICT capacity planner           | 3                    |\n",
      "| embedded systems security engineer | 3                    |\n",
      "| IT auditor                     | 3                    |\n",
      "| digital forensics expert       | 3                    |\n",
      "| database developer             | 3                    |\n",
      "| database administrator         | 2                    |\n",
      "| software analyst               | 2                    |\n",
      "| search engine optimisation expert | 2                    |\n",
      "| enterprise architect           | 2                    |\n",
      "| database integrator            | 2                    |\n",
      "| ICT business analysis manager  | 2                    |\n",
      "| data engineer                  | 2                    |\n",
      "| data analyst                   | 2                    |\n",
      "| ICT business analyst           | 2                    |\n",
      "| ICT system analyst             | 2                    |\n",
      "| ICT security technician        | 2                    |\n",
      "| ICT security administrator     | 2                    |\n",
      "| ICT network technician         | 2                    |\n",
      "| ICT network architect          | 2                    |\n",
      "| software architect             | 2                    |\n",
      "----------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Role</th>\n",
       "      <th>Matched Skills Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ICT resilience manager</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ICT security manager</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>ethical hacker</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ICT disaster recovery analyst</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ICT security consultant</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>chief ICT security officer</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ICT capacity planner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>embedded systems security engineer</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>IT auditor</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>digital forensics expert</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>database developer</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>database administrator</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>software analyst</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>search engine optimisation expert</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>enterprise architect</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>database integrator</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ICT business analysis manager</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>data engineer</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>data analyst</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ICT business analyst</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ICT system analyst</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ICT security technician</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ICT security administrator</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ICT network technician</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ICT network architect</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>software architect</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Job Role  Matched Skills Count\n",
       "20              ICT resilience manager                     6\n",
       "23                ICT security manager                     6\n",
       "63                      ethical hacker                     5\n",
       "9        ICT disaster recovery analyst                     4\n",
       "22             ICT security consultant                     4\n",
       "38          chief ICT security officer                     3\n",
       "6                 ICT capacity planner                     3\n",
       "60  embedded systems security engineer                     3\n",
       "34                          IT auditor                     3\n",
       "56            digital forensics expert                     3\n",
       "54                  database developer                     3\n",
       "52              database administrator                     2\n",
       "71                    software analyst                     2\n",
       "70   search engine optimisation expert                     2\n",
       "62                enterprise architect                     2\n",
       "55                 database integrator                     2\n",
       "4        ICT business analysis manager                     2\n",
       "48                       data engineer                     2\n",
       "46                        data analyst                     2\n",
       "5                 ICT business analyst                     2\n",
       "26                  ICT system analyst                     2\n",
       "24             ICT security technician                     2\n",
       "21          ICT security administrator                     2\n",
       "17              ICT network technician                     2\n",
       "15               ICT network architect                     2\n",
       "72                  software architect                     2"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cybersecurity_analyst_skills = [\"Network security\",\n",
    "        \"SIEM (e.g., Splunk)\",\n",
    "        \"Threat analysis\",\n",
    "        \"Vulnerability assessment\",\n",
    "        \"Firewalls and intrusion detection systems\",\n",
    "        \"Risk assessment\",\n",
    "        \"Incident response\",\n",
    "        \"Encryption techniques\",\n",
    "        \"Security policies\",\n",
    "        \"Linux\"]\n",
    "found_skills = match_skills_esco_fuzzy(cybersecurity_analyst_skills, threshold=85)\n",
    "\n",
    "match_skills_job(found_skills)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code defines a two-step pipeline for matching user-provided skills to the ESCO skills taxonomy using sentence embeddings and cosine similarity. The prepare_esco_embeddings() function takes a raw set of ESCO skills, cleans it by removing empty strings and extra whitespace, and then uses the pre-trained Sentence-BERT model (all-MiniLM-L6-v2) to encode the cleaned skills into numerical embeddings. These embeddings represent the semantic meaning of each skill in vector space. The match_user_skills() function then preprocesses the user's input skills (e.g., lowercasing, stripping whitespace), encodes them using the same SBERT model, and compares them to the ESCO embeddings using cosine similarity. For each user skill, it identifies the top matching ESCO skill(s) and returns the results in a DataFrame showing the original user skill, the closest matched ESCO skill, and their similarity score. This approach enables semantic matching even when the exact phrasing of skills differs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_skill_embeddings(raw_skills):\n",
    "    \"\"\"\n",
    "    Cleans and encodes a set of ESCO skills using SBERT.\n",
    "    Returns the cleaned skill list, model, and embeddings.\n",
    "    \"\"\"\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "    # Case 1: Dictionary input\n",
    "    if isinstance(raw_skills, dict):\n",
    "        items = [\n",
    "            k.strip() for k in raw_skills.keys()\n",
    "            if isinstance(k, str) and k.strip() != ''\n",
    "        ]\n",
    "        embeddings = model.encode(items)\n",
    "        return items, model, embeddings, raw_skills\n",
    "\n",
    "    # Case 2: List or set input\n",
    "    elif isinstance(raw_skills, (list, set)):\n",
    "        items = [\n",
    "            s.strip() for s in raw_skills\n",
    "            if isinstance(s, str) and s.strip() != ''\n",
    "        ]\n",
    "        embeddings = model.encode(items)\n",
    "        return items, model, embeddings, None\n",
    "\n",
    "    else:\n",
    "        raise TypeError(\"Input must be a list, set, or dictionary.\")\n",
    "\n",
    "\n",
    "def match_user_skills(user_skills, skills, embeddings, model, threshold=0.7, top_k=1):\n",
    "    \"\"\"\n",
    "    Matches user-entered skills to a set of reference skills using cosine similarity.\n",
    "    Returns a nicely printed DataFrame of best matches and the matched skills list.\n",
    "    \"\"\"\n",
    "    matched_skills = []\n",
    "    user_skills = [preprocess_text(skill) for skill in user_skills]\n",
    "    user_embeddings = model.encode(user_skills)\n",
    "\n",
    "    records = []\n",
    "\n",
    "    for i, user_emb in enumerate(user_embeddings):\n",
    "        sims = cosine_similarity([user_emb], embeddings)[0]\n",
    "        top_indices = sims.argsort()[::-1][:top_k]\n",
    "\n",
    "        best_match_idx = top_indices[0]\n",
    "        best_score = sims[best_match_idx]\n",
    "\n",
    "        if best_score >= threshold:\n",
    "            matched_skill = skills[best_match_idx]\n",
    "            matched_skills.append(matched_skill)\n",
    "        else:\n",
    "            matched_skill = \"No Match\"\n",
    "\n",
    "        records.append({\n",
    "            \"User Skill\": user_skills[i],\n",
    "            \"Matched Skill\": matched_skill,\n",
    "            \"Cosine Similarity\": round(best_score, 3)\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(records)\n",
    "\n",
    "    # âœ… Pretty print\n",
    "    print(\"\\nðŸ“‹ Skill Matching Results\")\n",
    "    print(\"-\" * 60)\n",
    "    print(df.to_markdown(index=False))\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    return matched_skills\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "esco_skills, esco_model, esco_embeddings, _ = prepare_skill_embeddings(all_skills)\n",
    "\n",
    "anzsco_skills, anzsco_model, anzsco_embeddings, anzsco_lookup  = prepare_skill_embeddings(tool_to_category)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“‹ Skill Matching Results\n",
      "------------------------------------------------------------\n",
      "| User Skill                  | Matched Skill              |   Cosine Similarity |\n",
      "|:----------------------------|:---------------------------|--------------------:|\n",
      "| sql                         | sql server                 |               0.736 |\n",
      "| oracle mysql                | mysql                      |               0.714 |\n",
      "| backup recovery             | perform backup             |               0.731 |\n",
      "| performance tune            | No Match                   |               0.506 |\n",
      "| database security           | maintain database security |               0.91  |\n",
      "| store procedure             | No Match                   |               0.521 |\n",
      "| index                       | No Match                   |               0.368 |\n",
      "| data migration              | migrate exist data         |               0.747 |\n",
      "| monitor tool                | No Match                   |               0.655 |\n",
      "| script (e.g., bash, python) | No Match                   |               0.674 |\n",
      "------------------------------------------------------------\n",
      "\n",
      "ðŸ“‹ Skill Matching Results\n",
      "------------------------------------------------------------\n",
      "| User Skill                  | Matched Skill   |   Cosine Similarity |\n",
      "|:----------------------------|:----------------|--------------------:|\n",
      "| sql                         | No Match        |               0.687 |\n",
      "| oracle mysql                | mysql           |               0.714 |\n",
      "| backup recovery             | No Match        |               0.281 |\n",
      "| performance tune            | No Match        |               0.552 |\n",
      "| database security           | No Match        |               0.493 |\n",
      "| store procedure             | No Match        |               0.405 |\n",
      "| index                       | No Match        |               0.525 |\n",
      "| data migration              | No Match        |               0.574 |\n",
      "| monitor tool                | No Match        |               0.676 |\n",
      "| script (e.g., bash, python) | No Match        |               0.617 |\n",
      "------------------------------------------------------------\n",
      "\n",
      "ðŸ“‹ Skill Matching Results\n",
      "------------------------------------------------------------\n",
      "| User Skill                   | Matched Skill              |   Cosine Similarity |\n",
      "|:-----------------------------|:---------------------------|--------------------:|\n",
      "| database management software | database management system |               0.908 |\n",
      "------------------------------------------------------------\n",
      "\n",
      "ðŸ“‹ Matched Jobs (At Least 2 Skills Matched):\n",
      "----------------------------------------------------------\n",
      "| Job Role                       | Matched Skills Count |\n",
      "----------------------------------------------------------\n",
      "| data centre operator           | 5                    |\n",
      "| database administrator         | 5                    |\n",
      "| data warehouse designer        | 4                    |\n",
      "| database designer              | 4                    |\n",
      "| database developer             | 4                    |\n",
      "| system configurator            | 4                    |\n",
      "| database integrator            | 3                    |\n",
      "| ICT security administrator     | 2                    |\n",
      "| ICT system administrator       | 2                    |\n",
      "----------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Role</th>\n",
       "      <th>Matched Skills Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>data centre operator</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>database administrator</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>data warehouse designer</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>database designer</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>database developer</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>system configurator</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>database integrator</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ICT security administrator</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ICT system administrator</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Job Role  Matched Skills Count\n",
       "47        data centre operator                     5\n",
       "52      database administrator                     5\n",
       "51     data warehouse designer                     4\n",
       "53           database designer                     4\n",
       "54          database developer                     4\n",
       "75         system configurator                     4\n",
       "55         database integrator                     3\n",
       "21  ICT security administrator                     2\n",
       "25    ICT system administrator                     2"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skills = [\n",
    "        \"SQL\",\n",
    "        \"Oracle or MySQL\",\n",
    "        \"Backup and recovery\",\n",
    "        \"Performance tuning\",\n",
    "        \"Database security\",\n",
    "        \"Stored procedures\",\n",
    "        \"Indexing\",\n",
    "        \"Data migration\",\n",
    "        \"Monitoring tools\",\n",
    "        \"Scripting (e.g., Bash, Python)\"\n",
    "    ]\n",
    "esco_matches = match_user_skills(skills, esco_skills, esco_embeddings, esco_model, 0.70)\n",
    "\n",
    "anzsco_tool_matches = match_user_skills(skills, anzsco_skills, anzsco_embeddings, anzsco_model, 0.70)\n",
    "\n",
    "tools_found_list = []\n",
    "for tool in anzsco_tool_matches:\n",
    "    tools_found_list.append(tool_to_category[tool])\n",
    "\n",
    "esco_tool_matches = match_user_skills(tools_found_list, esco_skills, esco_embeddings, esco_model, 0.70)\n",
    "\n",
    "combined_matches = esco_tool_matches + esco_matches\n",
    "\n",
    "match_skills_job(combined_matches)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
